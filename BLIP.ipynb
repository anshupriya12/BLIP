{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff7b14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1399df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9484179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd4da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unconditional image captioning\n",
    "inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c13be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a woman sitting on the beach with her dog\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05a8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c09d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf00ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\Asus\\Downloads\\ADR_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41193e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store image filenames and captions\n",
    "image_captions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c29b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each image in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith((\".jpg\", \".jpeg\")):\n",
    "        # Load and process the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        raw_image = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Generate a caption for the image\n",
    "        out = model.generate(**inputs)\n",
    "        generated_caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        # Append the filename and caption to the list\n",
    "        image_captions.append((filename, generated_caption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dc1ee5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions saved to blip_image_captions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the captions to a CSV file\n",
    "output_csv = \"blip_image_captions.csv\"\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    caption_writer = csv.writer(csvfile)\n",
    "    caption_writer.writerow([\"Image Filename\", \"Caption\"])\n",
    "    caption_writer.writerows(image_captions)\n",
    "\n",
    "print(f\"Captions saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c21e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to blip_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model with pickle\n",
    "model_path = \"blip_model.pkl\"\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb31800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa503e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
